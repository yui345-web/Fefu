import logging
import tensorflow as tf
import numpy as np
from aiogram import Bot, Dispatcher, types
from aiogram.utils import executor
from aiogram.types import ParseMode
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer

# –í—Å—Ç–∞–≤—å —Å–≤–æ–π —Ç–æ–∫–µ–Ω –±–æ—Ç–∞
TOKEN = "8194961676:AAENyYv0SV_oi31MzAGAsd8XRSp5tMyFE_M"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞
bot = Bot(token=TOKEN, parse_mode=ParseMode.HTML)
dp = Dispatcher(bot)

# –í—Å—Ç–∞–≤—å –ø—É—Ç—å –¥–æ –º–æ–¥–µ–ª–∏
model = tf.keras.models.load_model(r"–ø—É—Ç—å –¥–æ –º–æ–¥–µ–ª–∏")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
VOCAB_SIZE = 20000
MAX_LEN = 25

# –°–æ–∑–¥–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä 
tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token="<OOV>")
tokenizer.fit_on_texts(["Hello!", "I am happy", "I feel sad", "What a surprise!"])

# –ö–ª–∞—Å—Å—ã
dataset_labels = ["joy", "sadness", "anger", "fear", "love", "surprise"]

# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ 4 –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
label_map = {
    "–†–∞–¥–æ—Å—Ç–Ω—ã–π": ["joy", "love"],
    "–ì—Ä—É—Å—Ç–Ω—ã–π": ["sadness"],
    "–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π": ["anger", "fear"],
    "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π": ["surprise"]
}

# –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
def predict_sentiment(text):
    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    sequence = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=MAX_LEN, padding="post")
    prediction = model.predict(sequence)[0]  # –ü–æ–ª—É—á–∞–µ–º –º–∞—Å—Å–∏–≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ 6 –∫–ª–∞—Å—Å–æ–≤ –≤ 4
    sentiment_probs = {sentiment: sum(prediction[dataset_labels.index(class_name)] for class_name in class_group)
                       for sentiment, class_group in label_map.items()}

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∞–º—ã–π –≤–µ—Ä–æ—è—Ç–Ω—ã–π –∫–ª–∞—Å—Å
    predicted_sentiment = max(sentiment_probs, key=sentiment_probs.get)

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏
    probs_text = "\n".join([f"{sentiment}: {round(prob * 100, 2)}%" for sentiment, prob in sentiment_probs.items()])

    return predicted_sentiment, probs_text

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start
@dp.message_handler(commands=["start"])
async def send_welcome(message: types.Message):
    await message.reply("–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ –ª—é–±–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∏ —è –æ–ø—Ä–µ–¥–µ–ª—é –µ–≥–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ!")

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
@dp.message_handler()
async def analyze_message(message: types.Message):
    sentiment, probs = predict_sentiment(message.text)
    await message.reply(f"üåü <b>–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å:</b> {sentiment}\n\nüìä <b>–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏:</b>\n{probs}")

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    executor.start_polling(dp, skip_updates=True)
